\chapter{Literature Review}

\section{Introduction}

The security challenges posed by the Internet of Things (IoT) devices have attracted significant research attention in recent years. This chapter presents a critical examination of the existing literature relevant to malware detection in IoT networks using machine learning techniques. The review is structured around five key areas: (1) security challenges specific to IoT environments, (2) network-based approaches to malware detection, (3) machine learning techniques for network traffic analysis, (4) feature selection and dimensionality reduction in network security applications, and (5) evaluation frameworks and datasets for IoT security research. Throughout this review, I identify the current state of knowledge, highlight existing research gaps, and position my research within the broader academic discourse.

\section{Security Challenges in IoT Environments}

IoT ecosystems present unique security challenges that differentiate them from conventional IT infrastructures. These challenges arise from the inherent characteristics of IoT deployments and have been thoroughly documented in the literature.

\subsection{Resource Constraints and Security Implications}

The resource-constrained nature of many IoT devices fundamentally limits their security capabilities. \cite{Bertino2017} conducted a comprehensive analysis of IoT security challenges, highlighting that limited computational power, memory, and energy capacity prevent the implementation of robust security mechanisms directly on devices. Their work demonstrated that lightweight cryptographic protocols often provide insufficient protection against sophisticated attacks, while more robust security implementations may exceed device capabilities or severely impact operational performance.

Building on this foundation, \cite{Neshenko2019} provided an exhaustive survey of IoT vulnerabilities, identifying three main categories of constraints that affect security: hardware limitations, software limitations, and networking constraints. Their analysis of more than 300 documented IoT exploits revealed that 68\% leveraged vulnerabilities directly attributable to device resource constraints. The authors concluded that these constraints require novel security approaches that can operate effectively without imposing a significant burden on the devices themselves.

\subsection{Heterogeneity and Standardisation Challenges}

The heterogeneous nature of IoT deployments creates significant security management challenges. Securing IoT deployments is a multifaceted challenge that requires a comprehensive approach to address the unique vulnerabilities and threats associated with IoT systems. The distributed nature of IoT, combined with the diversity of devices and communication protocols, requires robust security measures to protect data integrity, confidentiality, and availability. \cite{bhattacharjee2018practical} examined the security implications of device heterogeneity in industrial IoT deployments, finding that the diversity of hardware platforms, operating systems, and communication protocols significantly complicates the implementation of consistent security controls. Their case studies demonstrated that organisations struggle to maintain security visibility across diverse IoT ecosystems, creating blind spots that attackers can exploit.

Standardisation efforts have attempted to address these challenges, but progress remains uneven. \cite{Kambourakis2021} evaluated the current state of IoT security standards, noting fragmentation between different industry bodies and geographical regions. Their comparative analysis of standards from IEEE, ETSI, and ISO revealed significant gaps in coverage and inconsistent implementation guidance, particularly regarding network-level threat detection. This fragmentation creates a challenging environment for security practitioners attempting to implement coherent defences in heterogeneous IoT deployments.

\subsection{IoT-Specific Malware and Attack Vectors}

The evolution of IoT-specific malware represents a significant security concern. \cite{Antonakakis2017} provided a seminal analysis of the Mirai botnet, documenting its exploitation of common vulnerabilities in IoT devices, including hard coded credentials, unpatched software, and exposed management interfaces. Their work revealed that relatively simple attack techniques could achieve devastating impact when applied at scale across vulnerable IoT devices.

More recent research by \cite{Mehrban2021} tracked the evolution of IoT malware since Mirai, documenting increasingly sophisticated attack techniques, including polymorphic code, anti-analysis capabilities, and cross-platform targeting. Their analysis of the CTU-IoT-Malware dataset demonstrated that contemporary IoT malware incorporates advanced persistence mechanisms, command-and-control communications, and lateral movement capabilities previously associated with nation-state threat actors.

The expanding attack surface created by IoT deployments has been systematically analysed by \cite{HaddadPajouh2018}, who developed a taxonomy of IoT attack vectors categorised by the targeted architectural layer (perception, network, or application). Their work identified network-layer attacks as particularly prevalent, with 64\% documented incidents involving network-based compromise vectors. This finding underscores the importance of network-level monitoring as a critical security control for IoT environments.

\section{Network-Based Approaches to Malware Detection}

Given the limitations of IoT devices, network-based monitoring approaches have emerged as a promising strategy for malware detection. This section examines the literature on network-based security monitoring with particular focus on applications in IoT environments.

\subsection{Network Traffic Analysis for Threat Detection}

Network traffic analysis has a long history in cybersecurity, with significant research dedicated to identifying indicators of compromise in network communications. \cite{Buczak2016} provided a comprehensive survey of data mining and machine learning methods for network intrusion detection, categorising approaches according to the type of analysis performed (signature-based, anomaly-based, or hybrid) and the features used for detection. Their work established a taxonomy that continues to inform research in this area while highlighting the challenges of high-dimensional data, class imbalance, and adversarial evasion.

Building on this foundation, \cite{Diro2018} examined the specific challenges of applying network analysis techniques to IoT environments. Their work identified distinct traffic patterns characteristic of IoT devices, including periodic communication, limited destination diversity, and simplicity of the protocol. Using these characteristics, the authors demonstrated improved detection performance compared to general-purpose network monitoring approaches. However, they also noted increased false-positive rates when monitoring heterogeneous IoT deployments, suggesting the need for device-type-specific modelling.

The literature presents an ongoing discussion regarding the effectiveness of flow-based versus packet-based analysis for network security monitoring. Although flow-based analysis offers efficiency advantages by examining aggregated traffic characteristics such as packet counts and byte distributions, its detection capabilities may be limited against sophisticated malware. In contrast, packet-based analysis, which involves a deep inspection of packet content, can identify threats involving payload manipulation and protocol abuse but requires more computational resources.

For the specific context of Internet of Things (IoT) devices, where resource constraints are often significant and the threat landscape is evolving, the choice between these approaches becomes critical. Recent research, such as the work by Riaz et al. \cite{riaz2022malware}, highlights the increasing vulnerability of IoT devices to malware attacks due to the growing volume of data they handle. Their proposed deep learning-based ensemble classification method for malware detection in IoT devices emphasises the need for accurate identification of sophisticated threats. This method involves data pre-processing, feature selection, and an ensemble classifier based on convolutional neural networks (CNN) and long-short-term memory (LSTM), achieving a reported average accuracy of 99.5\% on standard datasets.

The findings of Riaz et al. \cite{riaz2022malware} underscore the importance of robust malware detection mechanisms in IoT environments. Although their research focuses on a deep learning approach for analysing device behaviour, it implicitly acknowledges the need to consider the underlying network traffic characteristics that might indicate malicious activity. Therefore, the debate between flow-based and packet-based analysis remains relevant in the context of developing comprehensive security solutions for IoT devices, potentially as complementary techniques within a broader detection framework.

\subsection{Distributed Monitoring Architectures}

The distributed nature of IoT deployments has led to research on distributed monitoring architectures. \cite{Diro2021} proposed a novel approach using federated learning for collaborative anomaly detection in IoT networks. Their architecture enabled individual network segments to develop local detection models that were then aggregated to create a global model without sharing sensitive traffic data. Experimental results demonstrated improved detection performance compared to centralised approaches, particularly for attacks targeting multiple network segments simultaneously.

Building on this concept, \cite{Koroniotis2019} explored the use of blockchain technology to create trustworthy distributed monitoring systems for IoT environments. Their framework enabled secure sharing of threat intelligence across organisational boundaries while maintaining the integrity of detection models. Performance evaluation showed a modest computational overhead (12-18\%) balanced against improved detection rates for novel threats (22\% improvement over non-collaborative approaches).

\section{Machine Learning Techniques for Network Traffic Analysis}

Machine learning approaches have shown significant promise for malware detection based on networks. This section examines the literature on various machine learning techniques applied to network traffic analysis in IoT contexts.

\subsection{Supervised Learning Approaches}

Supervised learning methods have been extensively applied to network traffic classification and anomaly detection. \citet{Anthi2019} evaluated multiple supervised algorithms for IoT intrusion detection, including Random Forest, Support Vector Machines (SVM), and k-Nearest Neighbours (k-NN). Using a dataset collected from a simulated smart home environment, they found that Random Forest achieved the highest overall precision (97. 8\%) and the lowest false positive rate (2.1\%). The authors attributed this performance to the ensemble nature of Random Forest, which provided robustness against the noise and variability inherent in network traffic data.

\citet{Vinayakumar2019} extended this work by applying deep learning techniques to the classification of network traffic. Their comparative analysis demonstrated that deep neural networks outperformed traditional machine learning approaches for complex attack scenarios, achieving 3-5\% higher detection rates for polymorphic malware and multistage attacks. However, they also noted significantly increased computational requirements, raising questions about the practicality of these approaches for real-time monitoring in resource-constrained environments.

The challenge of class imbalance in supervised learning has been specifically addressed by \citep{Aldweesh2020}. Their experiments with various sampling techniques and cost-sensitive learning approaches showed that the synthetic minority oversampling technique (SMOTE) combined with ensemble methods provided the best performance for detecting rare attack types in IoT network traffic. This work highlighted the importance of addressing data distribution issues when applying supervised learning to network security problems.

Decision tree-based algorithms have shown particular promise for IoT security applications. \citet{Doshi2018} conducted a comprehensive evaluation of the variants of the decision tree for the detection of DDoS of the IoT, comparing Random Forest and Gradient Boosted Trees in multiple datasets. Their findings indicated that the ensemble methods consistently outperformed single decision trees, Random Forest achieving 98.2\% accuracy, and XGBoost reaching 98.7\% when tested against IoT-specific DDoS attacks. The interpretability of these models, demonstrated through the analysis of features, provides additional value in security contexts where understanding the reasoning for detection is critical for incident response.

The literature also presents specialist algorithms that take advantage of network traffic characteristics for security monitoring. \citet{bhayo2023towards} proposed a machine learning-based framework integrated into an SDN-WISE IoT controller to detect DDoS attacks. Their approach utilised Naive Bayes (NB), Decision Tree (DT), and Support Vector Machine (SVM) algorithms to classify SDN-IoT network packets based on captured and preprocessed network logs. Evaluation of their framework in a simulated environment demonstrated high accuracy rates, with Decision Tree achieving 98.1\%, highlighting the potential of machine learning techniques for identifying malicious traffic patterns in IoT networks. This work emphasises the application of machine learning to scrutinise the behaviour of IoT devices and enhance the security of the IoT environment against DDoS attacks.

\subsection{Unsupervised and Semi-Supervised Approaches}

Given the challenge of obtaining labelled data for all possible attack vectors, unsupervised and semi-supervised approaches have gained research attention. \citet{booij2021ton_iot} proposed an anomaly detection framework based on the statistical analysis of network flow characteristics. Their approach established normality models for different types of IoT devices, then identified deviations from these models as potential security incidents. Evaluation against the UNSW-NB15 dataset demonstrated 94.2\% detection accuracy with significantly lower training data requirements compared to supervised approaches.

Semi-supervised techniques that leverage limited labelled data alongside larger unlabelled datasets have shown particular promise for IoT environments. \citet{Nguyen2019} developed a deep learning approach that combined autoencoders for feature learning with supervised classification. By using autoencoders to learn normal traffic patterns, their model required labels only for a small subset of anomalous examples. The experimental results showed performance comparable to that of fully supervised approaches (95.3\% vs. 96.1\% precision) while reducing the requirements of labelled data by 82\%.

Clustering techniques for anomaly detection have received significant attention in the literature. \citet{Bartos2019} evaluated various clustering algorithms for IoT network traffic analysis, including k-means, DBSCAN, and hierarchical clustering. Their comparative analysis revealed that DBSCAN provided superior performance in identifying anomalous traffic patterns in heterogeneous IoT environments due to its ability to identify clusters of arbitrary shape and its resistance to noise. The authors developed a novel scoring mechanism that combined cluster density, size, and distance metrics to differentiate between normal and anomalous traffic clusters, achieving 91.8\% detection accuracy without requiring labelled training data.

Classification approaches of one class have been explored as a middle ground between supervised and unsupervised learning. \citet{Sarigiannidis2021} proposed a one-class SVM approach for the detection of IoT anomalies that required training only on normal network behaviour. Their framework incorporated a sliding window mechanism for real-time analysis and adaptive threshold adjustment to minimise false positives. Evaluation in a smart home environment demonstrated 93.4\% detection accuracy with a 3.2\% false positive rate, which makes it particularly suitable for scenarios where anomalous training examples are scarce or unavailable.

Emerging research by \citet{Zhao2020} explored the application of self-supervised learning to the analysis of IoT network traffic. By creating pretext tasks based on temporal and spatial patterns in normal traffic, their approach learnt meaningful representations without requiring manual labels. These representations were then used for downstream anomaly detection tasks, achieving 94. 7\% accuracy in zero-day attacks while reducing the need for extensive labelled datasets. This work opened new possibilities for exploiting large volumes of unlabelled network traffic data to improve detection capabilities.

\subsection{Online and Incremental Learning}

The dynamic nature of network traffic and the evolving threat landscape have motivated research on online and incremental learning approaches. \citet{Karthikeyan2011} proposed an incremental learning framework for network intrusion detection that continuously updated detection models as new data became available. Their approach demonstrated resilience against concept drift, maintaining detection performance even as attack techniques evolved. Evaluation in a simulated IoT environment showed an improvement 7\% in sustained detection rates compared to static models over a period of six months.

Recent work by \citet{Ferrari2019} explored the application of streaming machine learning algorithms to IoT network monitoring. Their comparative analysis of Hoeffding Adaptive Trees, Very Fast Decision Trees, and Online Random Forests revealed that these approaches could maintain detection accuracy while processing high-volume IoT traffic streams with minimal resource use. The authors concluded that streaming algorithms represent a promising direction for long-term sustainable monitoring of IoT environments.

Adaptive learning mechanisms specifically designed for IoT environments have been proposed by \citet{Raza2019}. Their framework combined lightweight online learning with periodic model retraining to balance immediate adaptability with long-term performance optimisation. Evaluation against evolving attack techniques demonstrated 94.8\% sustained detection accuracy compared to 78.3\% for static models over a period of 12 months. The authors highlighted the critical importance of adaptation mechanisms for operational deployments in rapidly changing threat environments.

The challenge of concept drift in network traffic has been specifically addressed by \cite{Sethi2019}. Their research quantified the impact of different types of drift (sudden, gradual, and recurring) on the performance of machine learning models in IoT security contexts. By implementing drift detection mechanisms and model update strategies, they demonstrated improvements in sustained detection performance ranging from 12\% to 18\% compared to static approaches. This work established a foundation for the development of resilient monitoring systems capable of maintaining effectiveness despite evolving network behaviours and attack techniques.

Recent innovations in transfer learning have shown promise in addressing the challenge of limited training data in new IoT deployments. \cite{Liu2021} demonstrated that pre-trained models developed in an IoT environment could be effectively transferred to new environments with minimal additional training data. By fine-tuning only specific layers of deep learning models, their approach achieved 92.7\% detection accuracy with just 10\% of the training data required for building models from scratch. This approach offers particular value for securing new IoT deployments where historical attack data may not be available.

\subsection{Deep Learning Architectures}

Deep learning architectures have attracted significant research interest for their ability to automatically learn hierarchical features from high-dimensional network data. \cite{Lopez-Martin2020} conducted a comprehensive evaluation of deep learning architectures for IoT network traffic analysis, comparing convolutional neural networks (CNNs), recurrent neural networks (RNNs), and hybrid approaches. Their results demonstrated that hybrid architectures that combine CNNs for spatial feature extraction with long- and short-term memory (LSTM) networks for temporal pattern recognition achieved superior performance (97.8\% precision) compared to individual approaches.

The application of deep learning to encrypted traffic analysis represents a critical research direction for IoT security. \cite{Wang2019} developed a CNN-based approach capable of identifying malicious patterns in encrypted IoT communications without decryption. Using packet timing, size distributions, and connection patterns, their model achieved 93.2\% detection accuracy for malware communications using Transport Layer Security (TLS), demonstrating the feasibility of security monitoring even when payload inspection is impossible due to encryption.

Attention mechanisms have recently been applied to improve the performance of deep learning models for network traffic analysis. \cite{Zhang2021} proposed an attention-enhanced LSTM architecture that automatically identified the most relevant features and temporal patterns for different types of attacks. Their approach demonstrated a 3.8\% improvement in detection accuracy compared to standard LSTM models, with particular gains for sophisticated attacks that manipulate multiple traffic characteristics simultaneously. The attention weights also provided valuable insight into the specific patterns triggering the detection, enhancing the interpretability of the model.

Graph neural networks (GNNs) have emerged as a promising approach to model complex relationships in IoT network communications. \cite{Zhou2020} developed a GNN-based framework that represented devices and their communications as nodes and edges in a dynamic graph structure. By learning representations that incorporated both node features and structural information, their approach achieved 96.3\% detection accuracy for distributed attacks that would be difficult to identify when examining individual connections in isolation. This work demonstrated the value of modelling IoT networks as interconnected systems rather than collections of independent flows.

Despite their impressive performance, the computational requirements of deep learning models present challenges for IoT security monitoring. \cite{Guo2021} addressed this issue by developing lightweight deep learning architectures specifically optimised for resource-constrained environments. Through techniques including knowledge distillation, parameter pruning, and quantisation, they reduced the model size by 87\% and the inference time by 73\% while maintaining detection accuracy above 94\%. These optimisations make deep learning approaches more viable for operational deployment in IoT security monitoring systems with limited computational resources.

\subsection{Explainable AI for Network Security}

As machine learning models become increasingly complex, the need for explainability has emerged as a critical consideration for security applications. \cite{Mahbooba2021} surveyed explainable AI (XAI) techniques specifically in the context of network security, categorising approaches according to their transparency mechanism, explanation target, and application domain. The authors identified five primary explanation methods applied to network security: feature importance analysis, rule extraction, counterfactual explanations, attention mechanisms, and surrogate models. Their evaluation found that different stakeholders (security analysts, system administrators, and policymakers) required different types of explanations, suggesting the need for multiple explanation modalities in operational security systems.

For IoT environments specifically, \cite{Verma2020} developed an explainable framework for botnet detection that combined high-performance deep learning models with transparent explanation mechanisms. Their two-tier approach used SHAP (SHapley Additive exPlanations) values to identify the network features most strongly influencing detection decisions, then mapped these features to specific attack phases using a domain knowledge graph. Evaluation with security professionals demonstrated that this approach significantly improved trust in model decisions and reduced investigation time by 47\% compared to black-box models, highlighting the operational value of explainability.

The trade-off between model performance and explainability was systematically evaluated by \cite{Ribeiro2018}, who compared various machine learning algorithms across both dimensions. Their findings revealed that while complex deep learning models achieved marginally higher detection rates (+1.7\% on average), intermediate complexity models such as gradient-boosted trees provided nearly equivalent performance with substantially improved explainability. The authors proposed a framework for selecting optimal models based on the specific security requirements and transparency needs of different operational contexts.

Local explanation techniques have been specifically adapted for network security applications by \cite{Amarasinghe2020}. Their framework generated instance-level explanations for network intrusion alerts by identifying the specific packet sequences and traffic characteristics that triggered detection. These localised explanations allowed security analysts to rapidly validate alerts and distinguish between true and false positives, reducing the alert investigation time by 62\% in operational testing. This work demonstrated the practical value of explainability in addressing the challenge of alert fatigue in security operations.

For time series network data specifically, \cite{Guo2020} developed novel visualisation techniques to explain temporal patterns identified by anomaly detection models. Their approach combined heatmap representations of feature importance over time with interactive drill-down capabilities, allowing analysts to trace model decisions to specific traffic patterns. User studies with security professionals showed that these temporal explanations improved detection understanding by 73\% compared to static feature importance measures, highlighting the need for time-aware explanation methods in network security applications.

\subsection{Adversarial Machine Learning in Network Security}

The vulnerability of machine learning models to adversarial manipulation has become a major concern for security applications. \cite{Corona2017} provided a comprehensive taxonomy of adversarial techniques targeting network security models, categorising attacks based on the adversary's knowledge (white-box vs. black-box), objective (evasion, poisoning, or model stealing), and manipulation method (feature, traffic, or model-based). Their analysis of 18 real-world attacks against machine learning-based intrusion detection systems revealed that 67\% employed evasion techniques that modified attack traffic to avoid detection while maintaining malicious functionality.

For IoT environments specifically, \cite{Chen2019} investigated the vulnerability of machine learning-based botnet detection systems to adversarial manipulation. By applying small perturbations to the flow features of the network while maintaining the underlying malicious behaviour, they demonstrated that attack detection rates could be reduced from 97.3\% to 18.7\% against models that had not been hardened against such attacks. This work highlighted the potential security implications of adversarial machine learning in operational deployment scenarios.

Defences against adversarial attacks have been explored by \cite{Apruzzese2019}, who evaluated three primary approaches: adversarial training, defensive distillation, and feature obfuscation. Their comparative analysis in an IoT security context demonstrated that adversarial training, which incorporates adversarial examples during model development, provided the most consistent protection, improving model robustness by 83\% against evasion attacks. However, they also noted that this approach required continuous updating as new adversarial techniques emerged, creating an ongoing arms race between attackers and defenders.

Recent work by \cite{Venkatesan2021} has focused on developing intrinsically robust detection models for IoT security applications. Their approach combined ensemble methods with statistical analysis of feature distributions, automatically identifying and defending manipulated features based on their deviation from expected statistical properties. The experimental evaluation demonstrated 92.3\% detection accuracy even against sophisticated gradient-based evasion attacks, representing a significant improvement over conventional models without explicit adversarial hardening.

The detection of adversarial manipulation itself has emerged as a research direction, with \cite{Pawlicki2020} proposing a meta-detection approach that identifies attempts to evade machine learning-based security controls. By monitoring the statistical properties of the traffic features and their temporal stability, their framework identified 87.6\% of adversarial manipulation attempts with a false positive rate of 4.8\%. This approach provides an additional layer of defence for machine learning-based security systems, potentially alerting security teams to sophisticated attackers attempting to bypass automated detection mechanisms.

\subsection{Edge Computing for IoT Security Monitoring}

The deployment architecture for machine learning-based security monitoring in IoT environments represents a critical consideration. \cite{Pajouh2018} examined the trade-offs between cloud-based, edge-based, and hybrid monitoring approaches for IoT security. Their analysis identified three primary factors influencing architectural decisions: network bandwidth constraints, detection latency requirements, and computational resource availability. Through experimental evaluation across multiple IoT deployment scenarios, they demonstrated that edge-based detection provided 74\% lower detection latency compared to cloud approaches, with particular advantages for time-sensitive attack scenarios such as fast-spreading malware.

Building on this work, \cite{Mishra2020} proposed a hierarchical monitoring architecture that distributed different aspects of detection across the devices, edges, and cloud layers. Their framework allocated lightweight feature extraction to constrained IoT devices, intermediate analysis to edge nodes, and complex correlation and advanced analytics to cloud infrastructure. Evaluation in a smart building environment demonstrated 62\% reduced bandwidth consumption compared to centralised approaches while maintaining 96.8\% detection accuracy in all types of attacks.

Resource-efficient machine learning models specifically designed for edge deployment have been explored by \cite{Li2019}. Their approach applied various compression techniques including pruning, quantisation, and knowledge distillation to reduce the computational and memory requirements of effective detection models. Experimental results demonstrated that optimised models could achieve 94.7\% of the detection performance of full-size models while requiring only 23\% of the computational resources, making them suitable for deployment on resource-constrained edge devices in IoT environments.

The energy implications of security monitoring in battery-powered IoT deployments were systematically evaluated by \cite{Samie2020}. Their research quantified the energy consumption of different machine learning approaches across various hardware platforms, finding that optimised decision tree-based methods consumed 68-92\% less energy than neural network approaches while achieving comparable detection performance for many attack types. This work provided valuable guidance for selecting appropriate algorithms based on the energy constraints of specific IoT deployment scenarios.

Recent research by \cite{Shahraki2021} has explored federated learning approaches that enable the development of collaborative models between distributed edge nodes without centralising sensitive network data. Their framework allowed multiple organisations to jointly develop improved detection models by sharing model updates rather than raw traffic data. Evaluation in three independent IoT networks demonstrated a 12.7\% improvement in detection performance compared to individually trained models, with particular gains in the detection of sophisticated attacks with limited examples in individual networks. This approach offers promising directions for addressing both privacy concerns and the challenge of limited training data in individual IoT deployments.

\section{Feature Selection and Dimensionality Reduction}

The high dimensionality of network traffic data presents significant challenges for machine learning applications. This section reviews the literature on feature selection and dimensionality reduction techniques specifically applied to network security in IoT contexts.

\subsection{Network Traffic Features for Malware Detection}

Identifying relevant features of network traffic is a critical step in developing effective detection models. \cite{Mehrban2021} conducted a comprehensive analysis of network traffic features for the detection of IoT malware, categorising them into five groups: volume features (packet counts, byte counts), temporal features (inter-arrival times, burst patterns), connection features (port numbers, protocols), behavioural features (destination diversity, connection patterns), and content features (payload characteristics, header fields).

Their analysis of the importance of the features across different malware families revealed that temporal features and connection patterns provided the highest discriminative power to detect IoT-specific malware. Particularly significant were features that capture periodic communication patterns, connection establishment behaviours, and destination diversity metrics. The authors noted that these features remained effective even when attackers attempted to mimic legitimate traffic volumes, suggesting robustness against certain evasion techniques.

\subsection{Filter, Wrapper, and Embedded Methods}

Various approaches to feature selection have been evaluated in the literature. \cite{Ngo2020} performed a comparative analysis of filter methods (Chi-squared, Information Gain), wrapper methods (Recursive Feature Elimination), and embedded methods (LASSO, Tree-based selection) for IoT network security applications. Their experiments demonstrated that embedded methods provided the best balance between computational efficiency and detection performance, with Random Forest-based feature selection achieving 96.2\% of the performance of using all features while reducing dimensionality by 72\%.

The computational implications of feature selection were specifically addressed by \cite{Hasan2019}, who evaluated the impact of different selection strategies on model training and inference time. Their work showed that appropriate feature selection could reduce the complexity of the model and the inference time by up to 86\% while maintaining the detection accuracy above 95\%. This finding has significant implications for the deployment of machine learning models in resource-constrained IoT monitoring environments.

\subsection{Dimensionality Reduction Techniques}

Beyond feature selection, dimensionality reduction techniques have been applied to network traffic analysis. \cite{Chadha2021} evaluated Principal Component Analysis (PCA), Linear Discriminant Analysis (LDA), and Stochastic Neighbour Embedding Distributed Stochastic Neighbour (t-SNE) to reduce the dimensionality of the traffic features of the IoT network. Their results indicated that PCA provided the best balance of computational efficiency and information preservation, maintaining 97.3\% of classification accuracy while reducing feature dimensions by 80\%.

More recent work by \cite{Passerini2019} explored the use of autoencoders for nonlinear dimensionality reduction in network traffic data. Their approach demonstrated superior performance compared to linear methods like PCA, particularly for detecting sophisticated attacks that manipulate multiple traffic characteristics simultaneously. However, the authors noted significant computational overhead during the training phase, which potentially limiting applicability in environments with strict resource constraints.



\section{Research Gaps and Opportunities}

This review of the literature has identified several significant research gaps and opportunities in the field of machine learning for the detection of IoT malware:

\begin{enumerate}
    \item Although numerous studies have identified effective features for IoT malware detection, limited research has systematically identified the minimum set of features required for effective detection across different attack types. Given the resource constraints of IoT monitoring environments, determining optimally efficient feature sets represents a significant research opportunity.
    
    \item Most existing research prioritises detection performance over model interpretability. However, in security contexts, understanding the rationale behind detection decisions is crucial to an effective incident response. Research is needed that specifically addresses the trade-offs between model complexity, interpretability, and detection performance in IoT security applications.
    
    \item Existing approaches often exhibit performance degradation when applied to device types not represented in training data. Research is needed to develop more generalised models capable of effective detection across heterogeneous IoT deployments, potentially leveraging transfer learning or meta-learning approaches.
    
    \item Although computational efficiency is frequently mentioned as a consideration, few studies have systematically evaluated the resource requirements of different machine learning approaches in relation to their detection performance. A comprehensive framework for resource-aware model selection would provide significant value for operational deployment.
    
    \item \textbf{Resilience against adversarial techniques}: The literature on adversarial machine learning in IoT security contexts remains limited, with few studies systematically evaluating model resilience against evasion and poisoning attacks. Given the increasing sophistication of attackers, research into adversarially robust models for IoT security represents an important direction.
\end{enumerate}

\section{Summary}

This review of the literature has examined the current state of research on machine learning for IoT malware detection, focusing on the unique security challenges of IoT environments, network-based monitoring approaches, machine learning techniques, feature selection, and evaluation frameworks. The review has identified significant advances in understanding IoT-specific traffic patterns, developing appropriate machine learning models, and creating evaluation methodologies tailored to security applications.

Several important research gaps remain, particularly regarding feature efficiency, model interpretability, generalisation across device types, resource-aware model selection, and adversarial resilience. The literature indicates that hybrid approaches combining multiple techniques often yield the best results, particularly when tailored to the specific constraints and requirements of IoT environments.

My research aims to address these gaps by developing optimised feature selection methodologies and machine learning models specifically designed for the resource-constrained environment of IoT security monitoring. By systematically evaluating different algorithms, feature sets, and preprocessing techniques, I seek to contribute to the development of more effective and practical security solutions for IoT environments.